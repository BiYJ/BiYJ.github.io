<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title> pthread 的同步机制		 | D</title><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style-dark.css?v=2.0.3"><link rel="stylesheet" type="text/css" href="/css/highlight-dark.css?v=2.0.3"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden"> pthread 的同步机制		</h1><a id="logo" href="/.">D</a><p class="description">While there is life there is hope</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title"> pthread 的同步机制		</h1><div class="post-meta"><a href="/2019/03/04/pthread-e7-9a-84-e5-90-8c-e6-ad-a5-e6-9c-ba-e5-88-b6/#comments" class="comment-count"></a><p><span class="date">Mar 04, 2019</span><span><a href="/categories/多线程/" class="category">多线程</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><p>原文：<a href="https://casatwy.com/pthreadde-ge-chong-tong-bu-ji-zhi.html" title="Permalink to pthread的各种同步机制" target="_blank" rel="noopener">pthread的各种同步机制</a></p>
<h5 id="一、简述"><a href="#一、简述" class="headerlink" title="一、简述"></a>一、简述</h5><p>pthread 是 POSIX 标准的多线程库，UNIX、Linux 上广泛使用，windows 上也有对应的实现，共一百多个函数都是 pthread 开头。</p>
<p>多线程编程被普遍认为复杂，主要是因为多线程给程序引入了一定的不可预知性，要控制这些不可预知性，就需要使用各种锁各种同步机制，不同的情况就应该使用不同的锁、不同的机制。什么事情一旦放到多线程环境，要考虑的问题立刻就上升了好几个量级。多线程编程就像潘多拉魔盒，带来的好处不可胜数，然而只要一不小心，就很容易让程序失去控制，所以你得用各种锁各种机制管住它。要解决好这些问题，工程师们就要充分了解这些锁机制，分析不同的场景，选择合适的解决方案。</p>
<h5 id="二、Mutex-Lock-互斥锁"><a href="#二、Mutex-Lock-互斥锁" class="headerlink" title="二、Mutex Lock 互斥锁"></a>二、Mutex Lock 互斥锁</h5><p>MUTual-EXclude Lock 互斥锁。</p>
<p>它是最容易理解、使用最广泛的一种同步机制。顾名思义，被这个锁保护的临界区就只允许一个线程进入，其它线程如果没有获得锁权限，那就只能在外面等着。</p>
<p>它使用得非常广泛，以至于大多数人谈到锁就是 mutex。pthread 里面还有很多锁，mutex 只是其中一种。</p>
<p>1、相关宏和函数</p>
<p>PTHREAD_MUTEX_INITIALIZER // 用于静态的mutex的初始化，采用默认的attr。比如: static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;</p>
<p>int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr); // 用于动态的初始化<br>int pthread_mutex_destroy(pthread_mutex_t <em>mutex);  // 把 mutex 锁干掉，并且释放所有它所占有的资源<br>int pthread_mutex_lock(pthread_mutex_t </em>mutex);     // 请求锁，如果当前 mutex 已经被锁，那么这个线程就会卡在这儿，直到 mutex 被释放<br>int pthread_mutex_unlock(pthread_mutex_t <em>mutex);   // 解锁<br>int pthread_mutex_trylock(pthread_mutex_t </em>mutex);  // 尝试请求锁，如果当前 mutex 已经被锁或者不可用，这个函数就直接 return 了，不会把线程卡住</p>
<p>2、注意 mutex 的初始化</p>
<p>mutex 的初始化分两种，一种是用宏（PTHREAD_MUTEX_INITIALIZER），一种是用函数（pthread_mutex_init）。</p>
<p>如果没有特殊的配置要求的话，使用宏比较好，因为它比较快。只有真的需要配置的时候，才需要用函数。也就是说，凡是pthread_mutex_init(&amp;mutex, NULL) 的地方都可以使用宏，因为在 pthread_mutex_init 这个函数里的实现其实也是用了 PTHREAD_MUTEX_INITIALIZER：</p>
<p>///////////////////// pthread_src/include/pthread/pthread.h</p>
<p>#define PTHREAD_MUTEX_INITIALIZER __PTHREAD_MUTEX_INITIALIZER</p>
<p>///////////////////// pthread_src/sysdeps/generic/bits/mutex.h</p>
<p>#  define __PTHREAD_MUTEX_INITIALIZER \<br>{ __PTHREAD_SPIN_LOCK_INITIALIZER, __PTHREAD_SPIN_LOCK_INITIALIZER, 0, 0, 0, 0, 0, 0 }  // mutex 锁本质上是一个 spin lock，空转锁，关于空转锁的东西在下面会提到。</p>
<p>///////////////////// pthread_src/sysdeps/generic/pt-mutex-init.c<br>int<br>_pthread_mutex_init (pthread_mutex_t <em>mutex,<br>                     const pthread_mutexattr_t </em>attr)<br>{<br>    *mutex = (pthread_mutex_t) __PTHREAD_MUTEX_INITIALIZER;   // 这里其实用的也是宏。就这一句是初始化，下面都是在设置属性。</p>
<pre><code>if (! attr
    || memcmp (attr, &amp;\_\_pthread\_default_mutexattr, sizeof (*attr) == 0))
/\* The default attributes.  */
    return 0;

if (! mutex-&gt;attr
    || mutex-&gt;attr == \_\_PTHREAD\_ERRORCHECK_MUTEXATTR
    || mutex-&gt;attr == \_\_PTHREAD\_RECURSIVE_MUTEXATTR)
    mutex-&gt;attr = malloc (sizeof *attr);                 // pthread\_mutex\_destroy 释放的就是这里的资源

if (! mutex-&gt;attr)
    return ENOMEM;

\*mutex-&gt;attr = \*attr;
return 0;
</code></pre><p>}</p>
<p>但是业界有另一种说法是：早年的 POSIX 只支持在 static 变量上使用 PTHREAD_MUTEX_INITIALIZER，所以PTHREAD_MUTEX_INITIALIZER 尽量不要到处都用，所以使用的时候得搞清楚你的 pthread 的实现版本是不是比较老的。</p>
<h5 id="三、mutex-锁不是万能灵药"><a href="#三、mutex-锁不是万能灵药" class="headerlink" title="三、mutex 锁不是万能灵药"></a>三、mutex 锁不是万能灵药</h5><p>基本上所有的问题都可以用互斥的方案去解决，大不了就是慢点儿，但不要不管什么情况都用互斥，都能采用这种方案不代表都适合采用这种方案。而且这里所说的慢不是说 mutex 的实现方案比较慢，而是互斥方案影响的面比较大，本来不需要通过互斥就能让线程进入临界区，用了互斥方案之后，就使这样的线程不得不等待互斥锁的释放，所以就慢了。</p>
<p>甚至有些场合用互斥就很蛋疼，比如多资源分配，线程步调通知等。如果是读多写少的场合，就比较适合读写锁（reader/writter lock），如果临界区比较短，就适合空转锁（pin lock）。</p>
<h5 id="四、预防死锁"><a href="#四、预防死锁" class="headerlink" title="四、预防死锁"></a>四、预防死锁</h5><p>如果要进入一段临界区需要多个 mutex 锁，那么就很容易导致死锁，单个 mutex 锁是不会引发死锁的。要解决这个问题也很简单，只要申请锁的时候按照固定顺序，或者及时释放不需要的 mutex 锁就可以。这就对代码有一定的要求，尤其是全局 mutex 锁的时候，更需要遵守一个约定。</p>
<p>如果是全局 mutex 锁，我习惯将它们写在同一个头文件里。一个模块的文件再多，都必须要有两个 umbrella header file。一个是整个模块的伞，外界使用你的模块的时候，只要 include 这个头文件即可。另一个用于给模块的所有子模块去 include，然后这个头文件里面就放一些公用的宏、配置，全局 mutex 放在这里就最合适了。这两个文件不能是同一个，否则容易出循环include 的问题。如果有人写模块不喜欢写这样的头文件的，那现在就要改了。</p>
<p>然后我的 mutex 锁的命名规则就是：作用_mutex_序号，比如 LinkListMutex_mutex_1、OperationQueue_mutex_2，后面的序号在每次有新锁的时候 +1。如果有哪个临界区进入的时候需要获得多个 mutex 锁的，我就按照序号的顺序去进行加锁操作（pthread_mutex_lock），这样就能够保证不会出现死锁了。</p>
<p>如果是属于某个 struct 内部的 mutex 锁，那么也一样，只不过序号可以不必跟全局锁挂钩，也可以从 1 开始数。</p>
<p>还有另一种方案也非常有效，就是用 pthread_mutex_trylock 函数来申请加锁，这个函数在申请加锁失败时立刻返回错误：EBUSY（锁尚未解除）或者 EINVAL（锁变量不可用）。一旦在 trylock 的时候有错误返回，那就把前面已经拿到的锁全部释放，然后过一段时间再来一遍。 当然也可以使用 pthread_mutex_timedlock 这个函数来申请加锁，这个函数跟pthread_mutex_trylock 类似，不同的是，你可以传入一个时间参数，在申请加锁失败之后会阻塞一段时间等解锁，超时之后才返回错误。</p>
<p>这两种方案我更多会使用第一种，原因如下：</p>
<ul>
<li>一般情况下进入临界区需要加的锁数量不会太多，第一种方案足够。如果多于 2 个，就要考虑一下是否可以合并某些锁。</li>
</ul>
<p>第一种方案适合锁比较少的情况，因为这不会导致非常大的阻塞延时。但是当你要加的锁非常多，ABCDE，加锁到 D 的时候阻塞了，然而其他线程可能只需要 AB 就可以运行，就会因为 AB 已经被锁住而阻塞，这时候才会采用第二种方案。如果要加的锁本身就不多，只有 AB 两个，那么阻塞一下还可以接受。</p>
<ul>
<li>第二种方案在面临阻塞的时候，要操作的事情太多。</li>
</ul>
<p>当把已经拿到的所有的锁都释放以后，当前线程的处理策略就会导致你的代码复杂度上升：当前线程不能退出，需要找个地方把它放起来，让它去等待一段时间之后再去申请锁，如果有多个线程出现了这样的情况，就需要一个线程池来存放这些等待解锁的线程。如果临界区是嵌套的，你在把这个线程挂起的时候，最好还要把外面的锁也释放掉，要不然也会容易导致死锁，这就需要你在一个地方记录当前线程使用锁的情况。这里要做的事情太多，复杂度比较大，容易出错。</p>
<p>总而言之，设计的时候尽量减少同一临界区所需要 mutex 锁的数量，然后采用第一种方案。如果确实有需求导致多个 mutex 锁，那么就只能采用第二种方案了，然后老老实实写好周边代码。但是 umbrella header file 和按照序号命名 mutex 锁是个非常好的习惯，可以允许你随着软件的发展而灵活采取第一第二种方案。</p>
<p>但是到了 semaphore 情况下的死锁处理方案时，上面两种方案就都不顶用了。另外，还有一种自己把自己锁死的死锁。</p>
<h5 id="五、Reader-Writter-Lock-读写锁"><a href="#五、Reader-Writter-Lock-读写锁" class="headerlink" title="五、Reader-Writter Lock 读写锁"></a>五、Reader-Writter Lock 读写锁</h5><p>mutex 锁有个缺点，就是只要锁住了，不管其他线程要干什么，都不允许进入临界区。</p>
<p>设想这样一种情况：临界区 foo 变量在被 thread1 线程读着，加了个 mutex 锁，thread2 线程如果也要读 foo 变量，因为被 thread1 加了个互斥锁，那就不能读了。但事实情况是，读取数据不影响数据内容本身，所以即便被 1 个线程读着，另外一个线程也应该允许去读。除非另外一个线程是写操作，为了避免数据不一致的问题，写线程就需要等读线程都结束了再写。</p>
<p>因此诞生了 Reader-Writter Lock，有的地方也叫 Shared-Exclusive Lock，共享锁。</p>
<p>读写锁的特性：</p>
<p>当一个线程加了读锁访问临界区，另一个线程也想访问临界区读取数据的时候，也可以加一个读锁成功进入临界区进行读操作了，此时读锁线程有两个。当第三个线程需要进行写操作时，它需要加一个写锁，这个写锁只有在读锁的拥有者为 0 时才有效。也就是等前两个读线程都释放读锁之后，第三个线程就能进去写了。</p>
<p>总结，读写锁里，读锁能允许多个线程同时去读，但是写锁在同一时刻只允许一个线程去写。</p>
<p>这样更精细的控制，就能减少 mutex 导致的阻塞延迟时间。虽然用 mutex 也能起作用，但这种场合明显读写锁更好。</p>
<p>1、相关宏和函数</p>
<p>PTHREAD_RWLOCK_INITIALIZER</p>
<p>int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr);<br>int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);</p>
<p>int pthread_rwlock_rdlock(pthread_rwlock_t <em>rwlock);<br>int pthread_rwlock_tryrdlock(pthread_rwlock_t </em>rwlock);</p>
<p>int pthread_rwlock_wrlock(pthread_rwlock_t <em>rwlock);<br>int pthread_rwlock_trywrlock(pthread_rwlock_t </em>rwlock);</p>
<p>int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);</p>
<p>int pthread_rwlock_timedrdlock_np(pthread_rwlock_t *rwlock, const struct timespec *deltatime); // 这个函数在 Linux 和 Mac 的 man 文档里都没有，新版的pthread.h里面也没有，旧版的能找到<br>int pthread_rwlock_timedwrlock_np(pthread_rwlock_t *rwlock, const struct timespec *deltatime); // 同上</p>
<p>2、认真区分使用场合，记得避免写线程饥饿</p>
<p>跟上面提到的写 muetx 锁的约定一样，操作、类别、序号最好都要有。比如 OperationQueue_rwlock_1。</p>
<p>由于读写锁的性质，在默认情况下是很容易出现写线程饥饿的。因为它必须要等到所有读锁都释放之后才能成功申请写锁。不过不同系统的实现版本对写线程的优先级实现不同。Solaris 是写线程优先，其他系统默认读线程优先。</p>
<p>比如在写线程阻塞的时候，有很多读线程是可以一个接一个地在那儿插队的（在默认情况下，只要有读锁在，写锁就无法申请，然而读锁可以一直申请成功，就导致所谓的插队现象），那么写线程就不知道什么时候才能申请成功写锁了，然后它就饿死了。</p>
<p>为了控制写线程饥饿，必须要在创建读写锁的时候设置 PTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE，不要用PTHREAD_RWLOCK_PREFER_WRITER_NP，这个似乎没什么用。</p>
<p>////////////////////////////// /usr/include/pthread.h</p>
<p>/* Read-write lock types.  */</p>
<p>#if defined __USE_UNIX98 || defined __USE_XOPEN2K<br>enum<br>{<br>    PTHREAD_RWLOCK_PREFER_READER_NP,<br>    PTHREAD_RWLOCK_PREFER_WRITER_NP, // 妈蛋，没用，一样reader优先<br>    PTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP,<br>    PTHREAD_RWLOCK_DEFAULT_NP = PTHREAD_RWLOCK_PREFER_READER_NP<br>};</p>
<p>总的来说，这样的锁建立之后一定要设置优先级，不然就容易出现写线程饥饿。而且读写锁适合读多写少的情况，如果读、写一样多，那还是用 mutex 锁比较合理。</p>
<h5 id="六、spin-lock-空转锁"><a href="#六、spin-lock-空转锁" class="headerlink" title="六、spin lock 空转锁"></a>六、spin lock 空转锁</h5><p>spin lock 空转锁。它是互斥锁、读写锁的基础。在其它同步机制里 condition variable、barrier 等都有它的身影。</p>
<p>先说一下其他锁申请加锁的过程，你就知道什么是 spin lock 了。</p>
<p>互斥锁和读写锁在申请加锁时会使得线程阻塞。阻塞的过程分为两个阶段，第一阶段是会先空转，可以理解成跑一个 while 循环，不断地去申请锁，在空转一定时间之后，线程会进入 waiting 状态，此时线程不占用 CPU 资源了，等锁可用的时候，这个线程会被唤醒。</p>
<p>为什么会有这两个阶段呢？主要还是出于效率因素。</p>
<ul>
<li><p>如果在申请锁失败之后立刻将线程状态挂起，会带来上下文切换的开销，挂起之后就不占用 CPU 资源了，原属于这个线程的 CPU 时间就可以拿去做更加有意义的事情。假设锁在第一次申请失败之后就又可用了，那么短时间内进行上下文切换的开销就显得很没效率。</p>
</li>
<li><p>如果在申请锁失败之后不断轮询申请加锁，那么可以在第一时间申请加锁成功，同时避免了上下文切换的开销，但是浪费了宝贵的 CPU 时间。假设锁在第一次申请失败之后，很久很久才能可用，那么 CPU 在这段时间里都被这个线程拿来轮询了，也显得很没效率。</p>
</li>
</ul>
<p>于是就出现了两种方案结合的情况：在第一次申请加锁失败的时候，先不着急切换上下文，空转一段时间。如果锁在短时间内又可用了，那么就避免了上下文切换的开销，CPU 浪费的时间也不多。空转一段时间之后发现还是不能申请加锁成功，那么就有很大概率在将来的不短的一段时间里面加锁也不成功，那么就把线程挂起，把轮询用的 CPU 时间释放出来给别的地方用。</p>
<p>《APUE》中原文是这样：A spin lock is like a mutex, except that instead of blocking a process by sleeping, the process is blocked by busy-waiting (spinning) until the lock can be acquired.</p>
<p>事实上，spin lock 在实现的时候，有一个 __pthread_spin_count 限制，如果空转次数超过这个限制，线程依旧会挂起（__shed_yield）。</p>
<p>spin lock 申请加锁的实现：</p>
<p>/////////////////////////////pthread_src/sysdeps/posix/pt-spin.c</p>
<p>/* Lock the spin lock object LOCK.  If the lock is held by another<br> thread spin until it becomes available.  <em>/<br>int<br>_pthread_spin_lock (__pthread_spinlock_t </em>lock)<br>{<br>    int i;</p>
<pre><code>while (1)
{
    for (i = 0; i &lt; \_\_pthread\_spin_count; i++)
    {
        if (\_\_pthread\_spin_trylock (lock) == 0)
            return 0;
    }

    \_\_sched\_yield ();
}
</code></pre><p>}</p>
<p>1、相关宏和函数</p>
<p>在 man 里面没找到 spin lock 相关的函数，但事实上外面还是能够使用的，下面是在源代码里面挖到的原型：</p>
<p>////////////////////////////////pthread_src/pthread/pt-spin-inlines.c</p>
<p>/* Weak aliases for the spin lock functions.  Note that<br> pthread_spin_lock is left out deliberately.  We already provide an<br> implementation for it in pt-spin.c.  */<br>weak_alias (__pthread_spin_destroy, pthread_spin_destroy);<br>weak_alias (__pthread_spin_init, pthread_spin_init);<br>weak_alias (__pthread_spin_trylock, pthread_spin_trylock);<br>weak_alias (__pthread_spin_unlock, pthread_spin_unlock);</p>
<p>/////////////////////////////////pthread_src/sysdeps/posix/pt-spin.c</p>
<p>weak_alias (_pthread_spin_lock, pthread_spin_lock);</p>
<p>/<em>————————————————-</em>/</p>
<p>PTHREAD_SPINLOCK_INITIALIZER<br>int pthread_spin_init (__pthread_spinlock_t <em>__lock, int __pshared);<br>int pthread_spin_destroy (__pthread_spinlock_t </em>__lock);<br>int pthread_spin_trylock (__pthread_spinlock_t <em>__lock);<br>int pthread_spin_unlock (__pthread_spinlock_t </em>__lock);<br>int pthread_spin_lock (__pthread_spinlock_t *__lock);</p>
<p>/<em>————————————————-</em>/</p>
<p>2、分清楚使用场合</p>
<p>空转锁非常适合临界区非常短的场合，或者实时性要求比较高的场合。</p>
<p>由于临界区短，线程需要等待的时间也短，即便轮询浪费 CPU 资源，也浪费不了多少，省了上下文切换的开销。由于实时性要求比较高，来不及等待上下文切换的时间，那就只能浪费 CPU 资源在那儿轮询了。</p>
<p>大部分情况都不会直接用到空转锁，其他锁在申请不到加锁时也是会空转一定时间的，如果连这段时间都无法满足你的请求，那要么就是线程太多，或者临界区没那么短。</p>
<h5 id="七、pthread-cleanup-push-amp-pthread-cleanup-pop"><a href="#七、pthread-cleanup-push-amp-pthread-cleanup-pop" class="headerlink" title="七、pthread_cleanup_push() &amp; pthread_cleanup_pop()"></a>七、pthread_cleanup_push() &amp; pthread_cleanup_pop()</h5><p>线程是允许在退出的时候，调用一些回调方法的。如果你需要做类似的事情，那么就用以下这两种方法：</p>
<p>void pthread_cleanup_push(void (*callback)(void *), void *arg);<br>void pthread_cleanup_pop(int execute);</p>
<p>它的背后有一个 stack，可以塞很多个 callback 函数进去，然后调用的时候按照先入后出的顺序调用这些 callback。所以你在塞 callback 的时候，如果是关心调用顺序的，那就得注意这一点了。</p>
<p>塞进去的 callback 只有在以下情况下才会被调用：</p>
<ol>
<li>线程通过 pthread_exit() 函数退出 </li>
<li>线程被 pthread_cancel() 取消</li>
<li>pthread_cleanup_pop(int execute) 时，execute 传了一个非 0 值</li>
</ol>
<p>也就是说，如果你的线程函数是这么写的，那在线程结束的时候就不会调到你塞进去的那些 callback 了：</p>
<p>static void <em> thread_function(void </em>args)<br>{<br>    …<br>    …<br>    …<br>    …<br>    return 0;  // 线程退出时没有调用 pthread_exit() 退出，而是直接 return，此时是不会调用栈内 callback 的<br>}</p>
<p>用 exit() 行吗？只要在任意线程调用 exit()，整个进程就结束了。</p>
<p>pthread_cleanup_push 塞入的 callback 可以用来记录线程结束的点，或者打日志等，一般不太会在这里执行业务逻辑。在线程结束之后如果要执行业务逻辑，一般用下面提到的 pthread_join。</p>
<p>1、callback 函数是可以传参数的</p>
<p>在 pthread_cleanup_push 函数中，第二个参数的值会作为 callback 函数的第一个参数。举个例子：</p>
<p>void callback(void <em>callback_arg)<br>{<br>    printf(“arg is : %s\n”, (char </em>)callback_arg);<br>}</p>
<p>static void <em> thread_function(void </em>thread_arg)<br>{<br>    …<br>    pthread_cleanup_push(callback, “this is a queue thread, and was terminated.”);<br>    …<br>    pthread_exit((void <em>) 0);  // 这句不调用，线程结束就不会调用你塞进去的 callback 函数。<br>    return ((void </em>) 0);<br>}</p>
<p>int main ()<br>{<br>    …<br>    …<br>    error = pthread_create(&amp;tid, NULL, thread_function, (void *)thread_arg)<br>    …<br>    …<br>    return 0;<br>}</p>
<p>callback 函数的参数是在线程函数里面设置的，所以拿来做业务也是可以的，不过一般都是拿来做清理的事情，很少会把它放到业务里面去做。</p>
<p>2、要保持 callback 栈平衡</p>
<p>关于要在保持栈平衡的前提下，选择性地调用 callback，似乎只能在中间调用 *__handlers = __handler.next; 这句话了？也许这是个伪需求，关于这个问题，大家也可以在评论区讨论一下。</p>
<p>样例：</p>
<p>void callback1(void <em>callback_arg)<br>{<br>    printf(“arg is : %s\n”, (char </em>)callback_arg);<br>}</p>
<p>void callback2(void <em>callback_arg)<br>{<br>    printf(“arg is : %s\n”, (char </em>)callback_arg);<br>}</p>
<p>static void <em> thread_function(void </em>thread_arg)<br>{<br>    …</p>
<pre><code>pthread\_cleanup\_push(callback1, &quot;this is callback 1.&quot;);
pthread\_cleanup\_push(callback2, &quot;this is callback 2.&quot;);

...

if (thread\_arg-&gt;should\_callback) {
    pthread_exit((void *) result);
}

pthread\_cleanup\_pop(0);   // 传递参数0，在pop的时候就不会调用对应的callback，如果传递非0值，pop的时候就会调用对应callback了。
pthread\_cleanup\_pop(0);   // push 了两次就 pop 两次，你要是只 pop 一次就不能编译通过
pthread_exit((void *) result);

return ((void *) 0);
</code></pre><p>}</p>
<p>int main ()<br>{<br>    …<br>    …<br>    error = pthread_create(&amp;tid, NULL, thread_function, (void *)thread_arg)<br>    …<br>    …<br>    return 0;<br>}</p>
<p>push 和 pop 如果不一一对应，就会导致编译不过。事实的确如此，在 pthread 对于这两个函数是通过宏来实现的，如果没有一一对应，编译器就会报 “} missing” 的错误。其相关实现代码如下：</p>
<p>/* ./include/pthread/pthread.h */</p>
<p>#define pthread_cleanup_push(rt, rtarg) __pthread_cleanup_push(rt, rtarg)</p>
<p>#define pthread_cleanup_pop(execute) __pthread_cleanup_pop(execute)<br>/* ./sysdeps/generic/bits/cancelation.h */</p>
<p>#define __pthread_cleanup_push(rt, rtarg) \<br>    { \<br>      struct __pthread_cancelation_handler *<em>__handlers \<br>        = __pthread_get_cleanup_stack (); \<br>      struct __pthread_cancelation_handler __handler = \<br>        { \<br>          (rt), \<br>          (rtarg), \
          </em>__handlers \<br>        }; \<br>      *__handlers = &amp;__handler;</p>
<p>#define __pthread_cleanup_pop(execute) \<br>      if (execute) \<br>        __handler.handler (__handler.arg); \<br>       *__handlers = __handler.next; \<br>    } \</p>
<h5 id="八、pthread-join"><a href="#八、pthread-join" class="headerlink" title="八、pthread_join()"></a>八、pthread_join()</h5><p>在线程结束的时候，我们能通过上面的 pthread_cleanup_push 塞入的 callback 方法知道，也能通过 pthread_join 这个方法知道。一般情况下，如果是出于业务的需要要知道线程何时结束的，都会采用 pthread_join 这个方法。</p>
<p>它适用这样的场景：</p>
<blockquote>
<p>有两个线程，B 线程在做某些事情之前，必须要等待 A 线程把事情做完，然后才能接着做下去。这时候可以用 join。</p>
</blockquote>
<p>原型：</p>
<p>int pthread_join(pthread_t thread, void **value_ptr);</p>
<p>在 B 线程里调用这个方法，第一个参数传 A 线程的 thread_id，第二个参数你可以扔一个指针进去。当 A 线程调用pthread_exit(void *value_ptr) 来结束的时候，A 的 value_ptr 就会到 pthread_join 的 value_ptr 去，你可以理解成 A 把它计算出来的结果放到 exit 函数里面去，然后其他 join 的线程就能拿到这个数据了。</p>
<p>在 B 线程 join 了 A 线程之后，B 线程会阻塞住，直到 A 线程跑完。A 线程跑完之后，自动被 detach，后续再要 join 的线程就会报 EINVAL。</p>
<p>1、新创建的线程默认是 join 属性，每一个 join 属性的线程都需要通过 pthread_join 来回收资源</p>
<ul>
<li>如果 A 线程已经跑完，但没被 join 过，此时 B 线程要去 join A 线程的时候，pthread_join 是会立刻正确返回的，之后 A 线程就被 detach 了，占用的资源也会被释放。</li>
<li>如果 A 线程已经跑完，后面没人 join 它，它占用的资源就会一直在哪儿，变成僵尸线程。</li>
</ul>
<p>所以要么在创建线程的时候就把线程设置为 detach 的线程，这样线程跑完以后不用 join，占用的资源自动回收。</p>
<p>要么不要忘记去 join 一下，把资源回收。</p>
<p>2、注意传递的参数的内存生命周期</p>
<p>虽然线程和进程共享同一个进程资源，但如果在 pthread_exit() 里面你传递的指针指向的是栈内存，那么在结束之后，这片内存还是会被回收的，具体到使用的时候，不同的系统又是不同的方案。</p>
<p>一定要在获得 value_ptr 之后，检查一下 value_ptr 是否 PTHREAD_CANCELED，因为如果你要等待的线程被 cancel 掉了，你拿到的就是这个数据。</p>
<p>3、多个线程 join 同一个线程</p>
<p>pthread_join 是允许多个线程等待同一个线程的结束的。如果要一个线程等待多个线程的结束，那就需要用下面提到的条件变量，或者 barrier。</p>
<p>但是多个线程 join 同一个线程的时候，情况就比较多。先建立一个约定：A 线程是要被 join 的线程，BCDEF 是要等待 A 线程结束的线程。下面说一下每种情况：</p>
<ul>
<li>A 线程正在运行，BCDEF 线程发起对 A 的 join，发起 join 结束后，A 仍然在运行中</li>
</ul>
<p>此时 BCDEF 线程都会被阻塞，等待 A 线程的结束。A 线程结束之后，BCDEF 都被唤醒，能够正常获得 A 线程通过pthread_exit() 返回的数据。</p>
<ul>
<li>A 线程正在运行，BCDEF 线程发起对 A 的 join，BCD 发起 join 成功后，A 线程结束，然后 EF 发起 join</li>
</ul>
<p>此时 BCD 线程能够正常被唤醒，并完成任务，由于被 join 后 A 线程被 detach，资源释放，后续 EF 再要发起 join，就会EINVAL。</p>
<ul>
<li>A 线程正在运行，且运行结束。此时 BCDEF 发起对 A 的 join。</li>
</ul>
<p>此时谁先调用成功，谁就能完成任务，后续再要 join 的就都会 EINVAL。一旦有一个线程 join 成功，A 立刻被 detach，资源释放，然后后面其他的线程就都不会 join 成功。</p>
<p>总的来说，只要线程运行结束，并且被 detach 了，后面再 join 就不行了，只要线程还在运行中，就能 join。如果运行结束了，第一次被 join 之后，线程就被 detach 了，后续就不能 join。当然了，如果线程本来就是 detach 属性的线程，那任何时候都无法被 join。</p>
<h5 id="九、Condition-Variables-条件变量"><a href="#九、Condition-Variables-条件变量" class="headerlink" title="九、Condition Variables 条件变量"></a>九、Condition Variables 条件变量</h5><p>pthread_join 解决的是多个线程等待同一个线程的结束。条件变量能在合适的时候唤醒正在等待的线程。具体什么时候合适由你自己决定。它必须要跟互斥锁联合起来用。</p>
<p>场景：</p>
<p>B 线程和 A 线程之间有合作关系，当 A 线程完成某件事情之前，B 线程会等待。当 A 线程完成某件事情之后，需要让 B 线程知道，然后 B 线程从等待状态中被唤醒，然后继续做自己要做的事情。</p>
<p>如果不用条件变量的话，就是搞个 volatile 变量，然后让其他线程不断轮询，一旦这个变量到了某个值，就可以让线程继续。如果有多个线程需要修改这个变量，那就再加个互斥锁或者读写锁。</p>
<p>这做法太蠢，还特别浪费 CPU 时间。</p>
<p>大致的实现原理：</p>
<p>一个条件变量背后有一个池子，所有需要 wait 这个变量的线程都会进入这个池子。当有线程扔出这个条件变量的 signal，系统就会把这个池子里面的线程挨个唤醒。</p>
<p>1、相关宏和函数</p>
<p>PTHREAD_COND_INITIALIZER<br>int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr);<br>int pthread_cond_destroy(pthread_cond_t *cond);</p>
<p>int pthread_cond_signal(pthread_cond_t <em>cond);<br>int pthread_cond_broadcast(pthread_cond_t </em>cond);</p>
<p>int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);<br>int pthread_cond_timedwait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex, const struct timespec *restrict abstime);</p>
<p>原则上 pthread_cond_signal 是只通知一个线程，pthread_cond_broadcast 是用于通知很多线程。但 POSIX 标准也允许让 pthread_cond_signal 用于通知多个线程，不强制要求只允许通知一个线程。具体看各系统的实现。</p>
<p>另外，在调用 pthread_cond_wait 之前，必须要申请互斥锁，当线程通过 pthread_cond_wait 进入 waiting 状态时，会释放传入的互斥锁。</p>
<p>下面先给一个条件变量的使用例子，然后再讲需要注意的点。</p>
<p>void thread_waiting_for_condition_signal ()<br>{<br>    pthread_mutex_lock(&amp;mutex);<br>    while (operation_queue == NULL) {<br>        pthread_cond_wait(&amp;condition_variable_signal, &amp;mutex);<br>    }</p>
<pre><code>/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/
/\* 做一些关于operation_queue的事 */
/*********************************/

pthread\_mutex\_unlock(&amp;mutex);
</code></pre><p>}</p>
<p>void thread_prepare_queue ()<br>{<br>    pthread_mutex_lock(&amp;mutex);</p>
<pre><code>/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/
/\* 做一些关于operation_queue的事 */
/*********************************/

pthread\_cond\_signal(&amp;condition\_variable\_signal); // 事情做完了之后要扔信号给等待的线程告诉他们做完了
pthread\_mutex\_unlock(&amp;mutex);


/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/
/\* 这里可以做一些别的事情 */
/**************************/

...

pthread_exit((void *) 0);
</code></pre><p>}</p>
<p>1、一定要跟 mutex 配合使用</p>
<p>void thread_function_1 ()<br>{<br>    done = 1;<br>    pthread_cond_signal(&amp;condition_variable_signal);<br>}</p>
<p>void thread_function_2 ()<br>{<br>    while (done == 0) {<br>        pthread_cond_wait(&amp;condition_variable_signal, NULL);<br>    }<br>}</p>
<p>这样当然不行。</p>
<p>这里有非常精巧的情况：在 thread_function_2 发现 done = 0 的时候，准备要进行下一步的 wait 操作。在具体开始下一步的 wait 操作之前，thread_function_1 完成了设置 done，发送信号的事情。thread_function_2 还没来得及 waiting，thread_function_1 就把信号发出去了，也没人接收这信号，thread_function_2 继续执行 waiting 之后，就只能一直等待。</p>
<p>2、一定要检测你要操作的内容</p>
<p>void thread_function_1 ()<br>{<br>    pthread_mutex_lock(&amp;mutex);</p>
<pre><code>...
operation\_queue = create\_operation_queue();
...

pthread\_cond\_signal(&amp;condition\_variable\_signal);
pthread\_mutex\_unlock(&amp;mutex);
</code></pre><p>}</p>
<p>void thread_function_2 ()<br>{<br>    pthread_mutex_lock(&amp;mutex);<br>    …<br>    pthread_cond_wait(&amp;condition_variable_signal, &amp;mutex);<br>    …<br>    pthread_mutex_unlock(&amp;mutex);<br>}</p>
<p>这样当然不行。</p>
<p>比如 thread_function_1 直接执行完，operation_queue 也初始化好了，信号也扔出去了。这时候 thread_function_2 刚刚启动，由于它没有去先检查 operation_queue 是否可用，直接就进入 waiting 状态。然而事实是 operation_queue 早已搞定，再也不会收到 operation_queue 创建好的信号，thread_function_2 也不知道 operation_queue 已经好了，就只能一直等待。</p>
<p>3、一定要用 while 来检测要操作的内容而不是 if</p>
<p>void thread_function_1 ()<br>{<br>    pthread_mutex_lock(&amp;mutex);<br>    done = 1;<br>    pthread_cond_signal(&amp;condition_variable_signal);<br>    pthread_mutex_unlock(&amp;mutex);<br>}</p>
<p>void thread_function_2 ()<br>{<br>    pthread_mutex_lock(&amp;mutex);<br>    if (done == 0) {<br>        pthread_cond_wait(&amp;condition_variable_signal, &amp;mutex);<br>    }<br>    pthread_mutex_unlock(&amp;mutex);<br>}</p>
<p>这样行不行？大多数情况行，但是用 while 更加安全。</p>
<p>如果有别人写一个线程去把这个 done 设置成 0，期间没有申请 mutex 锁。那么这时用 if 去判断的话，由于线程已经从 wait 状态唤醒，它会直接做下面的事情，而全然不知 done 的值已经变了。</p>
<p>如果这时用 while 去判断的话，在 pthread_cond_wait 解除 wait 状态之后，会再去 while 判断一次 done 的值，只有这次done的值对了，才不会进入wait。如果这期间done被别的不长眼的线程给改了，while补充的那一次判断就帮了你一把，能继续进入waiting。</p>
<p>不过这解决不了根本问题哈，如果那个不长眼的线程在while的第二次判断之后改了done，那还是要悲剧。根本方案还是要在改done的时候加mutex锁。</p>
<p>总而言之，用if也可以，毕竟不太容易出现不长眼的线程改done变量不申请加mutex锁的。用while的话就多了一次判断，安全了一点，即便有不长眼的线程干了这么龌龊的事情，也还能hold住。</p>
<h4 id="扔信号的时候，在临界区里面扔，不要在临界区外扔"><a href="#扔信号的时候，在临界区里面扔，不要在临界区外扔" class="headerlink" title="扔信号的时候，在临界区里面扔，不要在临界区外扔"></a>扔信号的时候，在临界区里面扔，不要在临界区外扔</h4><p> void thread_function_1 ()<br>    {<br>        pthread_mutex_lock(&amp;mutex);<br>        done = 1;<br>        pthread_mutex_unlock(&amp;mutex);</p>
<pre><code>    pthread\_cond\_signal(&amp;condition\_variable\_signal);
}

void thread\_function\_2 ()
{
    pthread\_mutex\_lock(&amp;mutex);
    if (done == 0) {
        pthread\_cond\_wait(&amp;condition\_variable\_signal, &amp;mutex);
    }
    pthread\_mutex\_unlock(&amp;mutex);
} 
</code></pre><p>这样行不行？当然不行。为什么不行？《Advanced Programming in the UNIX Enviroment 3 Edtion》这本书里也把扔信号的事儿放在临界区外面了呢。</p>
<hr>
<p>插播：</p>
<p>（此处张扬同学指出《APUE》在这里有一段论述，在这里我把这段摘下来）</p>
<p>《APUE》中关于这个问题是这么描述的：</p>
<blockquote>
<p>When we put a message on the work queue, we need to hold the mutex, but we don’t need to hold the mutex when we signal the waiting threads. As long as it is okay for a thread to pull the message off the queue before we call cond_signal, we can do this after releasing the mutex.</p>
</blockquote>
<p>在临界区外扔signal这种做法需要满足一些前提，这种做法不属于一种普适做法。所以我认为在制定编程规范的时候，应该禁止这种做法。在<a href="http://pages.cs.wisc.edu/~remzi/OSTEP/threads-cv.pdf" target="_blank" rel="noopener">这份资料</a>的第5页也对这个问题有一段小的论证。它的建议也是<code>ALWAYS HOLD THE LOCK WHILE SIGNALING</code>。</p>
<p>上面提到的资料的原文如下：</p>
<p>TIP: ALWAYS HOLD THE LOCK WHILE SIGNALING<br>Although it is strictly not necessary in all cases, it is likely simplest and<br>best to hold the lock while signaling when using condition variables. The<br>example above shows a case where you must hold the lock for correctness;<br>however, there are some other cases where it is likely OK not to, but<br>probably is something you should avoid. Thus, for simplicity, hold the<br>lock when calling signal.<br>The converse of this tip, i.e., hold the lock when calling wait, is not just<br>a tip, but rather mandated by the semantics of wait, because wait always<br>(a) assumes the lock is held when you call it, (b) releases said lock when<br>putting the caller to sleep, and (c) re-acquires the lock just before returning.<br>Thus, the generalization of this tip is correct: hold the lock when<br>calling signal or wait, and you will always be in good shape. </p>
<p>插播结束</p>
<hr>
<blockquote>
<p>不行就是不行，哪怕是圣经上这么写，也不行。哼。</p>
</blockquote>
<p>就应该永远都在临界区里面扔条件信号，我画了一个高清图来解释这个事情，图比较大，可能要加载一段时间：</p>
<p><img src="https://casatwy.com/pics/pthread_lock/condition_variable.jpg" alt="image"></p>
<p>看到了吧，1的情况就是在临界区外扔信号的坏处。由于在临界区外，其他线程要申请加mutex锁是可以成功的，然后这个线程要是改了你的敏感数据，你就只能去哭了…</p>
<h1 id="semaphore-信号量"><a href="#semaphore-信号量" class="headerlink" title="semaphore 信号量"></a>semaphore 信号量</h1><p>pthread库里面藏了一个semaphore（感谢评论区张扬指正：semaphore是进程间PV，也属于posix标准的组成部分，故前面的说法并不准确。），man手册里面似乎也找不到semaphore相关的函数。</p>
<p>semaphore事实上就是我们学《操作系统》的时候所说的PV操作。 你也可以把它理解成带有数量控制的互斥锁，当<code>sem_init(&amp;sem, 0, 1);</code>时，他就是一个mutex锁了。</p>
<blockquote>
<p>场景：比如有3台打印机，有5个线程要使用打印机，那么semaphore就会先记录好有3台，每成功被申请一次，就减1，减到0时，后面的申请就会被拒绝。</p>
</blockquote>
<p>它也可以用mutex和条件变量来实现，但实际上还是用semaphore比较方便。</p>
<h3 id="相关函数"><a href="#相关函数" class="headerlink" title="相关函数"></a>相关函数</h3><p> int sem_destroy(sem_t <em>sem);<br>    int sem_init(sem_t </em>sem, int pshared, unsigned int value);</p>
<pre><code>int sem\_wait(sem\_t *sem); // 如果sempahore的数值还够，那就semaphore数值减1，然后进入临界区。也就是传说中的P操作。
int sem\_post(sem\_t *sem); // 这个函数会给semphore的值加1，也就是V操作。

int sem\_getvalue(sem\_t \*sem, int \*valp); // 注意了，它把semaphore的值通过你传进去的指针告诉你，而不是用这个函数的返回值告诉你。 
</code></pre><h3 id="要注意的地方"><a href="#要注意的地方" class="headerlink" title="要注意的地方"></a>要注意的地方</h3><h4 id="semaphore下的死锁"><a href="#semaphore下的死锁" class="headerlink" title="semaphore下的死锁"></a>semaphore下的死锁</h4><p>mutex下的死锁比较好处理，因为mutex只会锁一个资源(当semaphore的值为1时，就是个mutex锁)，按照顺序来申请mutex锁就好了。但是到了semaphore这里，由于资源数量不止1个，死锁情况就显得比较复杂。</p>
<p>要想避免死锁，即便采用前面提到的方案：按照顺序加锁，一旦出现加锁失败，就释放所有资源。这招也行不通。假设这样一个情况，当前系统剩余资源情况如下：</p>
<p>剩余资源：      全部系统资源<br>A:3             A:10<br>B:2             B:10<br>C:4             C:10 </p>
<p>此时有两个线程：t1, t2。</p>
<p>t1需要3个A，4个B，1个C<br>t2需要2个A，2个B，2个C  根据当前剩余资源列表来看，t2可以得到执行，不会出现死锁。 </p>
<p>假设我们采用旧方案：顺序申请加锁，加锁失败就释放。我们按照CPU时间来推演一个：</p>
<p> 1. t1申请3个A -&gt; 成功<br>    2. t2申请2个A -&gt; 失败，等待<br>    3. t1申请4个B -&gt; 失败，等待，并释放3个A<br>    4. t1申请3个A -&gt; 成功<br>    5. t2申请2个A -&gt; 失败，等待<br>    6. t1申请4个B -&gt; 失败，等待，并释放3个A<br>    7. t1申请3个A -&gt; 成功<br>    8. t2申请2个A -&gt; 失败，等待<br>    9. t1申请4个B -&gt; 失败，等待，并释放3个A<br>    … </p>
<p>发现没有，这时候t1和t2都得不到执行，但实际上系统的剩余资源是满足t2的要求的，但由于运气不好，抢资源抢不过t1，在有新的资源被释放之前，这俩线程就一直在那儿抢来抢去得不到执行了。</p>
<p>要解决这样的问题，就需要采用银行家算法，银行家算法描述起来很简单：获取所有候选线程的需求，随机取一个假设资源分配出去，看是否能够分配成功。如果不能，就换一个候选者，再进行资源分配。直到有线程满足需求为止。如果都不能满足，那就挂起所有线程，等待新的资源释放。</p>
<p>也就是可以理解成很多个人去贷款，银行家先假设你们都能按期还得起钱，按照你们的需求给你们派钱，不过这不是真的派出去了，只是先写在纸上，银行家一推算，卧槽，到后面会出现资金缺口，那就换一种派发方式，直到没有资金缺口为止。</p>
<p>说白了，你需要在你的程序里面建立一个资源分配者的角色，所有待分配资源的线程都去一个池子里排队，然后这个资源分配者一次只允许一个线程来请求资源，如果请求失败，就换下一个，如果池子里没有线程能够被满足需求，那就集体挂起，然后等有新的资源来了，就再把这些线程一个一个叫过来进行资源分配。</p>
<h1 id="Barriers"><a href="#Barriers" class="headerlink" title="Barriers"></a>Barriers</h1><p><code>Barrier</code>可以理解成一个mile stone。当一个线程率先跑到mile stone的时候，就先等待。当其他线程都到位之后，再从等待状态唤醒，继续做后面的事情。</p>
<blockquote>
<p>场景：超大数组排序的时候，可以采用多线程的方案来排序。比如开10个线程分别排这个超大数组的10个部分。必须要这10个线程都完成了各自的排序，你才能进行后续的归并操作。先完成的线程会挂起等待，直到所有线程都完成之后，才唤醒所有等待的线程。</p>
</blockquote>
<p>前面有提到过<code>条件变量</code>和<code>pthread_join</code>，前者是在做完某件事情通知其他线程，后者是在线程结束之后让其他线程能够获得执行结果。如果有多个线程同时做一件事情，用上面这两者可以有次序地进行同步。另外，用<code>semaphore</code>也可以实现<code>Barrier</code>的功能。</p>
<p>但是我们已经有<code>Barrier</code>了好吗！你们能不要把代码搞那么复杂吗！</p>
<h3 id="相关宏和函数"><a href="#相关宏和函数" class="headerlink" title="相关宏和函数"></a>相关宏和函数</h3><p>int pthread_barrier_init(pthread_barrier_t *barrier, const pthread_barrierattr_t *restrict attr, unsigned count);<br>int pthread_barrier_destroy(pthread_barrier_t <em>barrier);<br>int pthread_barrier_wait(pthread_barrier_t </em>barrier); </p>
<p><code>pthread_barrier_wait</code>在唤醒之后，会有两种返回值：<code>0</code>或者<code>PTHREAD_BARRIER_SERIAL_THREAD</code>，在众多线程中只会有一个线程在唤醒时得到<code>PTHREAD_BARRIER_SERIAL_THREAD</code>的返回，其他返回都是<code>0</code>。拿到<code>PTHREAD_BARRIER_SERIAL_THREAD</code>返回的，表示这是上天选择的主线程～</p>
<h4 id="要注意的地方-1"><a href="#要注意的地方-1" class="headerlink" title="要注意的地方"></a>要注意的地方</h4><p>其实<code>Barrier</code>很少被错用，因为本来也没几个函数。更多的情况是有人不知道有<code>Barrier</code>，然后用其他的方式实现了类似<code>Barrier</code>的功能。知道就好了。</p>
<h1 id="关于attr"><a href="#关于attr" class="headerlink" title="关于attr"></a>关于attr</h1><h4 id="thread"><a href="#thread" class="headerlink" title="thread"></a>thread</h4><p>创建thread的时候是可以设置attr的：<code>detachstate</code>、<code>guardsize</code>、<code>stackaddr</code>、<code>stacksize</code>。一般情况下我都是采取默认的设置。只有在我非常确定这个线程不需要跟其他线程协作的时候，我会把<code>detachstate</code>设置为<code>PTHREAD_CREATE_DETACHED</code>。</p>
<h4 id="mutex"><a href="#mutex" class="headerlink" title="mutex"></a>mutex</h4><p>创建mutex的时候也是可以设置attr的：<code>process-shared</code>、<code>robust</code>、<code>type</code>。一般情况下尽量不要出现跨进程的锁共享，万一有个相关进程被酒杀(kill 9)了，而且死之前它抱着锁没放，你后面的事情就麻烦了，基本无解。<code>process-shared</code>和<code>robust</code>就是跟跨进程有关。</p>
<p>关于<code>type</code>，我强烈建议显式设置为<code>PTHREAD_MUTEX_ERRORCHECK</code>。在Linux下，默认的<code>type</code>是<code>PTHREAD_MUTEX_NORMAL</code>。这在下面这种情况下会导致死锁：</p>
<p>void thread_function()<br>{<br>    pthread_mutex_lock(&amp;mutex);<br>    foo();<br>    pthread_mutex_unlock(&amp;mutex);<br>}</p>
<p>void foo()<br>{<br>    pthread_mutex_lock(&amp;mutex);<br>    pthread_mutex_unlock(&amp;mutex);<br>} </p>
<p>上面的代码看着很正常是吧？但由于在调用<code>foo</code>之前，<code>mutex</code>已经被锁住了，于是<code>foo</code>就停在那边等待<code>thread_function</code>释放<code>mutex</code>。但是！<code>thread_function</code>必须要等<code>foo</code>跑完才能解锁，然后现在<code>foo</code>被卡住了。。。</p>
<p>如果<code>type</code>设置为<code>PTHREAD_MUTEX_ERRORCHECK</code>，那在<code>foo</code>里面的<code>pthread_mutex_lock</code>就会返回<code>EDEADLK</code>。如果你要求执行<code>foo</code>的时候一定要处于mutex的临界区，那就要这么判断。</p>
<p>如果<code>type</code>设置为<code>PTHREAD_MUTEX_RECURSIVE</code>，也不会产生死锁，但不建议用这个。<code>PTHREAD_MUTEX_RECURSIVE</code>使用的场景其实很少，我一时半会儿也想不到哪个场景不得不采用<code>PTHREAD_MUTEX_RECURSIVE</code>。</p>
<p>嗯，其他应该没什么了吧。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这篇文章主要讲了pthread的各种同步机制相关的东西：mutex、reader-writter、spin、cleanup callbacks、join、condition variable、semaphore、barrier。其中cleanup callbacks不算是同步机制，但是我看到也有人拿这个作为同步机制的一部分写在程序中，这是不对的！所以我才写了一下这个。</p>
<p>文章很长，相信你们看到这里也不容易，看完了这篇文章，你对多线程编程的同步机制应该可以说比较了解了。但我还要说的是，多线程编程的复杂点不仅仅在于同步机制，例如多线程跟系统信号的协作、多线程创建进程后的协作和控制、多线程和I/O之间的协作和控制、函数的可重入性等，我看我什么时候有时间再写这些内容了。</p>
</div><div class="post-copyright"><blockquote><p>原文作者: BiYJ</p><p>原文链接: <a href="http://yoursite.com/2019/03/04/pthread-e7-9a-84-e5-90-8c-e6-ad-a5-e6-9c-ba-e5-88-b6/">http://yoursite.com/2019/03/04/pthread-e7-9a-84-e5-90-8c-e6-ad-a5-e6-9c-ba-e5-88-b6/</a></p><p>版权声明: 转载请注明出处(必须保留原文作者署名原文链接)</p></blockquote></div><div class="tags"></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/2019/03/05/lc-2/" class="pre"> LC 2		</a><a href="/2019/03/04/lazytableimages/" class="next"> LazyTableImages		</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-5"><a class="toc-link" href="#一、简述"><span class="toc-text">一、简述</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#二、Mutex-Lock-互斥锁"><span class="toc-text">二、Mutex Lock 互斥锁</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#三、mutex-锁不是万能灵药"><span class="toc-text">三、mutex 锁不是万能灵药</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#四、预防死锁"><span class="toc-text">四、预防死锁</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#五、Reader-Writter-Lock-读写锁"><span class="toc-text">五、Reader-Writter Lock 读写锁</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#六、spin-lock-空转锁"><span class="toc-text">六、spin lock 空转锁</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#七、pthread-cleanup-push-amp-pthread-cleanup-pop"><span class="toc-text">七、pthread_cleanup_push() &amp; pthread_cleanup_pop()</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#八、pthread-join"><span class="toc-text">八、pthread_join()</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#九、Condition-Variables-条件变量"><span class="toc-text">九、Condition Variables 条件变量</span></a></li></ol><li class="toc-item toc-level-4"><a class="toc-link" href="#扔信号的时候，在临界区里面扔，不要在临界区外扔"><span class="toc-text">扔信号的时候，在临界区里面扔，不要在临界区外扔</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#semaphore-信号量"><span class="toc-text">semaphore 信号量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#相关函数"><span class="toc-text">相关函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#要注意的地方"><span class="toc-text">要注意的地方</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#semaphore下的死锁"><span class="toc-text">semaphore下的死锁</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Barriers"><span class="toc-text">Barriers</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#相关宏和函数"><span class="toc-text">相关宏和函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#要注意的地方-1"><span class="toc-text">要注意的地方</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#关于attr"><span class="toc-text">关于attr</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#thread"><span class="toc-text">thread</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mutex"><span class="toc-text">mutex</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/06/13/WKWebView/">WKWebView</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/iOS 编译过程原理(2)/">iOS 编译过程原理(2)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/BFPRT算法/">BFPRT 算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/全排列/">全排列</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/01-背包/">0-1 背包</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/直接插入排序/">直接插入排序</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/armv7、armv7s、arm64/">armv7、armv7s、arm64</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/Archives配置/">Archives 配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/App-Thinning/">App Thinning</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/AFNetworking/">AFNetworking</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AFNetworking/">AFNetworking</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Flutter/">Flutter</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/GLSL/">GLSL</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Games/">Games</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Leetcode/">Leetcode</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MJRefresh/">MJRefresh</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mac/">Mac</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OC/">OC</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OPENGL/">OPENGL</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ReactiveCocoa/">ReactiveCocoa</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SDWebImage/">SDWebImage</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SpriteKit/">SpriteKit</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Xcode/">Xcode</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">algorithm</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/iOS/">iOS</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/内存管理/">内存管理</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/减治法/">减治法</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/分治法/">分治法</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/动态规划/">动态规划</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/变治法/">变治法</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/图像视频/">图像视频</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/多线程/">多线程</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习笔记/">学习笔记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工程发布/">工程发布</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/底层原理/">底层原理</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/性能优化/">性能优化</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/排序算法/">排序算法</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/效率-工具/">效率 | 工具</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据存储/">数据存储</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构/">数据结构</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构设计/">架构设计</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法相关/">算法相关</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/网络编程/">网络编程</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/视图-amp-动画/">视图 &amp; 动画</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机网络/">计算机网络</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/设计策略/">设计策略</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/阅读源码/">阅读源码</a><span class="category-list-count">8</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/排序算法/" style="font-size: 15px;">排序算法</a> <a href="/tags/动态规划/" style="font-size: 15px;">动态规划</a> <a href="/tags/分治法/" style="font-size: 15px;">分治法</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://www.liaoxuefeng.com/" title="廖雪峰的官方网站" target="_blank">廖雪峰的官方网站</a><ul></ul><a href="https://blog.ibireme.com/" title="ibireme" target="_blank">ibireme</a><ul></ul><a href="https://www.cnblogs.com/machao/" title="马在路上" target="_blank">马在路上</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">BiYJ.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.3"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.3" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>